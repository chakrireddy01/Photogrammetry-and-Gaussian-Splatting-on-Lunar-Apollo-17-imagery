# Photogrammetry-and-Gaussian-Splatting-on-Lunar-Apollo-17-imagery

# Photogrammetry and Gaussian Splatting Project Report

**Name:** Chakradhar Reddy  
**Student ID:** 1236312313

---

## üìå 1. Introduction

This project explores classical photogrammetry and modern rendering techniques to reconstruct and evaluate 3D models from Apollo 17 lunar surface imagery. The primary objective was to process a set of 15 real images using photogrammetry software such as Agisoft Metashape or COLMAP to generate a textured mesh model of the lunar surface.

I compared the original and simulated images using image quality metrics like SSIM and PSNR. Then, I added 10 more modified images to see if the 3D reconstruction becomes better with more viewpoints. This helped me to understand how extra views can affect the quality and detail of photogrammetric models.

---

## üõ∞Ô∏è 2. Part A - Photogrammetry from 15 Apollo Images

**Tools Used:** Agisoft Metashape

**Steps Taken:**
1. Imported the 15 high-resolution Apollo 17 images.
2. Aligned the photos using Structure-from-Motion (SfM).
3. Generated a dense point cloud.
4. Built a mesh and attempted texturing.

**Observations:**
- Alignment was successful.
- Dense cloud and mesh generation completed.
- Texturing was functional on 15-image dataset.

---

## üìä 3. Image Quality Metrics

To evaluate the quality of a synthetic view (as if generated by Gaussian Splatting), I applied a Gaussian blur to one of the original Apollo 17 images (`AS17-137-20903HR.png`). Then, using a Python script with the `scikit-image` library, I compared the original and blurred images using SSIM and PSNR.

**Results:**
- **SSIM (Structural Similarity Index):** 0.7419
- **PSNR (Peak Signal-to-Noise Ratio):** 24.38 dB

**Interpretation:**
- The SSIM score of ~0.74 indicates moderate structural similarity between the original and blurred image. While the overall structure remains recognizable, finer details are diminished.
- The PSNR value of ~24.38 dB shows that the blurred version retains decent visual quality but lacks high-frequency detail.

These metrics helped me understand how closely a simulated view compares to the real image and gave me a baseline for evaluating view fidelity.

---

## üß™ 4. Part B - Augmented Photogrammetry with Simulated Views

**Objective:**  
To test whether adding new views improves the photogrammetric model.

**Methodology:**
1. I selected 10 Apollo 17 images and made small changes like shifting the view or angle to create new versions that look like they were taken from different camera positions.
2. These simulated images were used to create novel views not present in the original 15-image set.
3. I combined the 10 new images with the original 15 to make a 25-image dataset.
4. I imported all 25 images into Metashape.
5. I ran photo alignment again to match key points across the entire dataset.
6. Then, I built a new dense point cloud using the combined image set.
7. I also generated a new mesh model using the updated cloud.

**Challenges:**
- I created 10 new views based on the professor‚Äôs instructions to simulate novel camera positions.
- Since the new images were visually similar to the originals, the texture generation had limited success.

**Results:**
- All 25 images were aligned successfully in Metashape.
- The dense point cloud was generated accurately.
- The mesh model was created, and the texture generation worked to some extent, but the improvement was minimal compared to the 15-image model.

---

## üñºÔ∏è 5. Photographs



-![image](https://github.com/user-attachments/assets/b3341c63-8e8a-4ca6-a2d4-270ff1d3180b)
 ![image](https://github.com/user-attachments/assets/a05a3241-4472-43c6-b0c0-1389a4cd48a7)
‚Äì 3D reconstruction using the original 15 Apollo 17 images  
- ![image](https://github.com/user-attachments/assets/303a8de7-63fd-4a24-81c5-70649e248b11)![image](https://github.com/user-attachments/assets/2491ab45-3512-40e6-b4da-384ce7e9efe3)![image](https://github.com/user-attachments/assets/39787fd5-4865-441c-8673-7aadddf37215)
-3D reconstruction after adding 10 simulated novel views  
- ![image](https://github.com/user-attachments/assets/b584d8e5-c1f9-4d9f-acc9-47f0efb75fc8)
‚Äì Image quality comparison between original and blurred view  

---

## üß† Summary

This project helped me understand how additional viewpoints influence 3D model reconstruction in photogrammetry. It also introduced me to the value of image-based metrics like SSIM and PSNR when evaluating the similarity of novel views.
"""
